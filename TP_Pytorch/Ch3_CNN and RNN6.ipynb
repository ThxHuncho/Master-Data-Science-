{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#Initialize a random tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0cac079b10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(1)    # reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3512e-27,  3.0673e-41,  5.7453e-44],\n",
       "        [ 0.0000e+00,         nan,  4.5576e-41],\n",
       "        [ 1.3733e-14,  6.4076e+07,  2.0706e-19],\n",
       "        [ 7.3909e+22,  2.4176e-12,  1.1625e+33],\n",
       "        [ 8.9605e-01,  1.1632e+33,  5.6003e-02]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From a uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5153, -0.4414, -0.1939],\n",
       "        [ 0.4694, -0.9414,  0.5997],\n",
       "        [-0.2057,  0.5087,  0.1390],\n",
       "        [-0.1224,  0.2774,  0.0493],\n",
       "        [ 0.3652, -0.3897, -0.0729]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(5, 3).uniform_(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the shape of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5, 3).uniform_(-1, 1)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation from lists & numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "z = torch.LongTensor([[1, 3], [2, 9]])\n",
    "print(z.type())\n",
    "# Cast to numpy ndarray\n",
    "print(z.numpy().dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.DoubleTensor\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# Data type inferred from numpy\n",
    "print(torch.from_numpy(np.random.rand(5, 3)).type())\n",
    "print(torch.from_numpy(np.random.rand(5, 3).astype(np.float32)).type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple mathematical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-9.5237e-02,  1.3944e-01, -1.5719e-03],\n",
      "        [ 9.8974e-01, -1.6816e-01,  8.2311e-01],\n",
      "        [-1.2762e+00,  6.6872e-04, -5.9525e-01],\n",
      "        [ 4.3277e-01,  1.6542e-02,  3.0079e-01],\n",
      "        [ 9.8996e-01,  1.7735e-01, -5.8985e-01]])\n"
     ]
    }
   ],
   "source": [
    "y = x * torch.randn(5, 3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.2189e-01,  9.5583e-02, -5.4559e-03],\n",
      "        [ 3.8307e-01,  2.5760e-01, -3.3489e-01],\n",
      "        [-2.7237e-01, -3.9267e-01, -4.2511e-01],\n",
      "        [-1.7613e+00,  7.7451e-02,  1.5184e+01],\n",
      "        [ 5.8684e-01, -1.0187e+00,  1.7620e+00]])\n"
     ]
    }
   ],
   "source": [
    "y = x / torch.sqrt(torch.randn(5, 3) ** 2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "tensor([[-0.4940, -0.2590, -0.4079],\n",
      "        [ 2.6326,  2.0696,  1.3860],\n",
      "        [-1.0185, -0.5821, -0.8459],\n",
      "        [ 0.5357,  0.9040,  1.4523],\n",
      "        [ 0.1006, -1.4205,  0.1770]])\n"
     ]
    }
   ],
   "source": [
    "print (x.size())\n",
    "y = x + torch.randn(5, 1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 15])\n",
      "torch.Size([50, 15])\n",
      "torch.Size([50, 1, 15])\n",
      "torch.Size([50, 15])\n",
      "\n",
      "torch.Size([10, 5, 15])\n",
      "torch.Size([5, 15, 10])\n",
      "torch.Size([10, 15, 5])\n",
      "torch.Size([10, 15, 5])\n"
     ]
    }
   ],
   "source": [
    "y = torch.randn(5, 10, 15)\n",
    "print(y.size())\n",
    "print(y.view(-1, 15).size())  # Same as doing y.view(50, 15)\n",
    "print(y.view(-1, 15).unsqueeze(1).size()) # Adds a dimension at index 1.\n",
    "print(y.view(-1, 15).unsqueeze(1).squeeze().size())\n",
    "print()\n",
    "print(y.transpose(0, 1).size())\n",
    "print(y.transpose(1, 2).size())\n",
    "print(y.transpose(0, 1).transpose(1, 2).size())\n",
    "print(y.permute(1, 2, 0).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 100, 15])\n",
      "torch.Size([50, 100, 15])\n"
     ]
    }
   ],
   "source": [
    "print(y.view(-1, 15).unsqueeze(1).expand(50, 100, 15).size())\n",
    "print(y.view(-1, 15).unsqueeze(1).expand_as(torch.randn(50, 100, 15)).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 30])\n",
      "torch.Size([2, 5, 10, 15])\n"
     ]
    }
   ],
   "source": [
    "# 2 is the dimension over which the tensors are concatenated\n",
    "print(torch.cat([y, y], 2).size())\n",
    "# stack concatenates the sequence of tensors along a new dimension.\n",
    "print(torch.stack([y, y], 0).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Advanced Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 4])\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "y = torch.randn(2, 3, 4)\n",
    "print(y[[1, 0, 1, 1]].size())\n",
    "\n",
    "# PyTorch doesn't support negative strides yet so ::-1 does not work.\n",
    "rev_idx = torch.arange(1, -1, -1).long()\n",
    "print(y[rev_idx].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolution, BatchNorm & Pooling Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv output size :  torch.Size([10, 32, 28, 28])\n",
      "Pool output size :  torch.Size([10, 32, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(10, 3, 28, 28))\n",
    "\n",
    "conv = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), stride=1, \n",
    "                 padding=1, bias=True)\n",
    "bn = nn.BatchNorm2d(num_features=32)\n",
    "pool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "\n",
    "output_conv = bn(conv(x))\n",
    "outpout_pool = pool(conv(x))\n",
    "\n",
    "print('Conv output size : ', output_conv.size())\n",
    "print('Pool output size : ', outpout_pool.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recurrent, Embedding & Dropout Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size :  torch.Size([5, 3, 20])\n",
      "GRU hidden states size :  torch.Size([5, 3, 100])\n",
      "GRU last hidden state size :  torch.Size([4, 5, 50])\n"
     ]
    }
   ],
   "source": [
    "inputs = [[1, 2, 3], [1, 0, 4], [1, 2, 4], [1, 4, 0], [1, 3, 3]]\n",
    "x = Variable(torch.LongTensor(inputs))\n",
    "\n",
    "embedding = nn.Embedding(num_embeddings=5, embedding_dim=20, padding_idx=1)\n",
    "drop = nn.Dropout(p=0.5)\n",
    "gru = nn.GRU(input_size=20, hidden_size=50, num_layers=2, batch_first=True, \n",
    "             bidirectional=True, dropout=0.3)\n",
    "\n",
    "emb = drop(embedding(x))\n",
    "gru_h, gru_h_t = gru(emb)\n",
    "\n",
    "print('Embedding size : ', emb.size())\n",
    "print('GRU hidden states size : ', gru_h.size())\n",
    "print('GRU last hidden state size : ', gru_h_t.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The functional API provides users a way to use these classes in a functional way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv output size :  torch.Size([10, 32, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "x = Variable(torch.randn(10, 3, 28, 28))\n",
    "filters = Variable(torch.randn(32, 3, 3, 3))\n",
    "conv_out = F.relu(F.dropout(F.conv2d(input=x, weight=filters, padding=1), \n",
    "                            p=0.5, training=True))\n",
    "\n",
    "print('Conv output size : ', conv_out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
