{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travaux Pratique : introduction PyTorch, Tensors et Tensor Operations\n",
    "\n",
    "PyTorch est la bibliothèque de tenseurs hautes performances la plus optimisée pour le calcul de tâches d'apprentissage en profondeur sur les GPU (unités de traitement graphique) et les CPU (unités centrales de traitement). PyTorch est une bibliothèque basée sur Python et l'outil Torch fourni par le groupe de recherche sur l'intelligence artificielle de Facebook, qui effectue du calcul scientifique. Les cas d'utilisation où il est le plus fréquemment utilisé incluent le traitement du langage naturel, le traitement d'image, la vision par ordinateur, l'analyse des données des médias sociaux et le traitement des données des capteurs. Bien que PyTorch fournisse une large collection de bibliothèques et de modules de calcul, trois modules sont très importants.\n",
    "\n",
    "La documentation est disponible sur ce [lien](https://pytorch.org/docs/stable/index.html)\n",
    "\n",
    "## 1 Utilisation Tensors\n",
    "\n",
    "## fonction basique\n",
    "**Nous pouvons vérifier si un objet en Python est un objet tenseur en utilisant la syntaxe suivante.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [12,23,34,45,56,67,78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_tensor(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La fonction is_storage vérifie si l'objet est stocké en tant qu'objet tenseur:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_storage(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maintenant, créons un objet contenant des nombres aléatoires de Torch, similaire à la bibliothèque NumPy. \n",
    "Nous pouvons vérifier le tenseur et le type de stockage. La documentation est disponible [ici](https://pytorch.org/docs/stable/generated/torch.rand.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randn(1,2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_storage(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.numel(y) # the total number of elements in the input Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L'objet y est un tenseur ; cependant, il n'est pas stocké. Pour vérifier le nombre total d'éléments dans l'objet tenseur d'entrée, \n",
    "la fonction d'élément numérique peut être utilisée. Le script suivant est un autre exemple de création de valeurs nulles \n",
    "dans un tenseur 2D et de comptage des éléments numériques qu'il contient. [documentation](https://pytorch.org/docs/stable/generated/torch.zeros.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.numel(torch.zeros(4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comme les opérations NumPy, la fonction eye crée une matrice diagonale, dont les éléments diagonaux ont des uns, et les éléments hors diagonale ont des zéros. La fonction eye peut être manipulée en fournissant l'option de dimension.** [documentation]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #importation de la biblio numpy \n",
    "x1 = np.array(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On peut créer des tensors à partir de array numpy [documentation](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 23, 34, 45, 56, 67, 78])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 23, 34, 45, 56, 67, 78], dtype=torch.int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut créer un tenseur unidimensionnel de pas de taille dont les valeurs sont régulièrement espacées du début à la fin, inclus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0000,  2.3333,  2.6667,  3.0000,  3.3333,  3.6667,  4.0000,  4.3333,\n",
       "         4.6667,  5.0000,  5.3333,  5.6667,  6.0000,  6.3333,  6.6667,  7.0000,\n",
       "         7.3333,  7.6667,  8.0000,  8.3333,  8.6667,  9.0000,  9.3333,  9.6667,\n",
       "        10.0000])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(2, 10, steps=25) #linear spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-10.0000,  -8.5714,  -7.1429,  -5.7143,  -4.2857,  -2.8571,  -1.4286,\n",
       "          0.0000,   1.4286,   2.8571,   4.2857,   5.7143,   7.1429,   8.5714,\n",
       "         10.0000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(-10, 10, steps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e-10, 2.6827e-09, 7.1969e-08, 1.9307e-06, 5.1795e-05, 1.3895e-03,\n",
       "        3.7276e-02, 1.0000e+00, 2.6827e+01, 7.1969e+02, 1.9307e+04, 5.1795e+05,\n",
       "        1.3895e+07, 3.7276e+08, 1.0000e+10])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logspace(start=-10, end=10, steps=15) #logarithmic spacing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procédé aléatoire \n",
    "\n",
    "La génération de nombres aléatoires est un processus courant en science des données pour générer ou rassembler des exemples de points de données dans un espace afin de simuler la structure des données. \n",
    "\n",
    "Des nombres aléatoires peuvent être générés à partir d'une distribution statistique, de deux valeurs quelconques ou d'une distribution prédéfinie. Comme les fonctions NumPy, le nombre aléatoire peut être généré à l'aide de l'exemple suivant. \n",
    "\n",
    "La distribution uniforme est définie comme une distribution où chaque résultat a une probabilité égale de se produire ; par conséquent, les probabilités d'événement sont constantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3409, 0.8690, 0.9251, 0.1052, 0.5562, 0.7348, 0.4306, 0.4040, 0.7967,\n",
       "        0.2775])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random numbers from a uniform distribution between the values \n",
    "# 0 and 1\n",
    "torch.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9182, 0.9273, 0.9845, 0.1164, 0.8071],\n",
       "        [0.8337, 0.7950, 0.6537, 0.0297, 0.9685],\n",
       "        [0.5582, 0.2454, 0.6831, 0.8529, 0.4715],\n",
       "        [0.0462, 0.0212, 0.9521, 0.3459, 0.4964]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(4, 5) \n",
    "# random values between 0 and 1 and fillied with a matrix of \n",
    "# size rows 4 and columns 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.2214e+00,  3.3436e+00, -9.1005e-01,  3.8819e-01,  1.8948e-04,\n",
       "        -1.2541e+00,  3.9365e-01, -9.2636e-01, -1.7877e+00,  2.7802e-01])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random numbers from a normal distribution, \n",
    "#with mean =0 and standard deviation =1\n",
    "torch.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0023,  0.9481, -0.5481, -0.1665, -0.7035],\n",
       "        [ 1.3833,  2.1726, -0.6313, -0.9048, -0.3696],\n",
       "        [ 0.6735, -0.5608,  0.6813, -0.0672, -0.0499],\n",
       "        [-0.0032,  1.2302,  0.8534,  0.1668, -0.1698]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(4, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pour sélectionner des valeurs aléatoires dans une plage de valeurs à l'aide d'une permutation aléatoire, il faut d'abord définir la plage.**\n",
    "\n",
    "**Cette plage peut être créée à l'aide de la fonction d'arrangement. Lorsque vous utilisez la fonction d'arrangement, vous devez définir la taille du pas, qui place toutes les valeurs dans un espace à distance égale. Par défaut, la taille du pas est 1.** [documentation](https://pytorch.org/docs/stable/generated/torch.randperm.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 2, 0, 3, 8, 1, 6, 4, 9, 5])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selecting values from a range, this is called random permutation\n",
    "torch.randperm(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#usage of range function \n",
    "torch.arange(10, 40,2) #step size 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
       "        28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10,40) #step size 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pour trouver les valeurs minimales et maximales dans un tenseur 1D, argmin et argmax peuvent être utilisés. La dimension doit être mentionnée si l'entrée est une matrice afin de rechercher des valeurs minimales le long des lignes ou des colonnes.** [documentation](https://pytorch.org/docs/stable/generated/torch.argmax.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MEHDIH~1\\AppData\\Local\\Temp/ipykernel_43832/929232333.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "torch.argmin(d,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 1, 2])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(d,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, créons un exemple de tenseur 2D et effectuons l'indexation et la concaténation en utilisant l'opération concat sur les tenseurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indexing and performing operation on the tensors\n",
    "x = torch.randn(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0190,  0.0220,  1.1532, -0.3393, -1.5380],\n",
      "        [-1.0248, -0.3781,  0.9257,  0.9247,  0.1825],\n",
      "        [-0.0737,  0.3147,  0.8504,  1.0534,  0.3692],\n",
      "        [ 0.0628, -0.3297, -1.7970,  0.8728,  0.7670]])\n",
      "torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0190,  0.0220,  1.1532, -0.3393, -1.5380],\n",
       "        [-1.0248, -0.3781,  0.9257,  0.9247,  0.1825],\n",
       "        [-0.0737,  0.3147,  0.8504,  1.0534,  0.3692],\n",
       "        [ 0.0628, -0.3297, -1.7970,  0.8728,  0.7670],\n",
       "        [ 0.0190,  0.0220,  1.1532, -0.3393, -1.5380],\n",
       "        [-1.0248, -0.3781,  0.9257,  0.9247,  0.1825],\n",
       "        [-0.0737,  0.3147,  0.8504,  1.0534,  0.3692],\n",
       "        [ 0.0628, -0.3297, -1.7970,  0.8728,  0.7670]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate two tensors\n",
    "torch.cat((x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0190,  0.0220,  1.1532, -0.3393, -1.5380],\n",
       "        [-1.0248, -0.3781,  0.9257,  0.9247,  0.1825],\n",
       "        [-0.0737,  0.3147,  0.8504,  1.0534,  0.3692],\n",
       "        [ 0.0628, -0.3297, -1.7970,  0.8728,  0.7670],\n",
       "        [ 0.0190,  0.0220,  1.1532, -0.3393, -1.5380],\n",
       "        [-1.0248, -0.3781,  0.9257,  0.9247,  0.1825],\n",
       "        [-0.0737,  0.3147,  0.8504,  1.0534,  0.3692],\n",
       "        [ 0.0628, -0.3297, -1.7970,  0.8728,  0.7670],\n",
       "        [ 0.0190,  0.0220,  1.1532, -0.3393, -1.5380],\n",
       "        [-1.0248, -0.3781,  0.9257,  0.9247,  0.1825],\n",
       "        [-0.0737,  0.3147,  0.8504,  1.0534,  0.3692],\n",
       "        [ 0.0628, -0.3297, -1.7970,  0.8728,  0.7670]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate n times based on array size\n",
    "torch.cat((x,x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0190,  0.0220,  1.1532, -0.3393, -1.5380,  0.0190,  0.0220,  1.1532,\n",
      "         -0.3393, -1.5380,  0.0190,  0.0220,  1.1532, -0.3393, -1.5380],\n",
      "        [-1.0248, -0.3781,  0.9257,  0.9247,  0.1825, -1.0248, -0.3781,  0.9257,\n",
      "          0.9247,  0.1825, -1.0248, -0.3781,  0.9257,  0.9247,  0.1825],\n",
      "        [-0.0737,  0.3147,  0.8504,  1.0534,  0.3692, -0.0737,  0.3147,  0.8504,\n",
      "          1.0534,  0.3692, -0.0737,  0.3147,  0.8504,  1.0534,  0.3692],\n",
      "        [ 0.0628, -0.3297, -1.7970,  0.8728,  0.7670,  0.0628, -0.3297, -1.7970,\n",
      "          0.8728,  0.7670,  0.0628, -0.3297, -1.7970,  0.8728,  0.7670]])\n",
      "torch.Size([4, 15])\n"
     ]
    }
   ],
   "source": [
    "#concatenate n times based on array size, over column\n",
    "concatenate_tensors = torch.cat((x,x,x),1)\n",
    "print(concatenate_tensors)\n",
    "print(concatenate_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0190,  0.0220,  1.1532, -0.3393, -1.5380],\n",
       "        [-1.0248, -0.3781,  0.9257,  0.9247,  0.1825],\n",
       "        [-0.0737,  0.3147,  0.8504,  1.0534,  0.3692],\n",
       "        [ 0.0628, -0.3297, -1.7970,  0.8728,  0.7670],\n",
       "        [ 0.0190,  0.0220,  1.1532, -0.3393, -1.5380],\n",
       "        [-1.0248, -0.3781,  0.9257,  0.9247,  0.1825],\n",
       "        [-0.0737,  0.3147,  0.8504,  1.0534,  0.3692],\n",
       "        [ 0.0628, -0.3297, -1.7970,  0.8728,  0.7670]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate n times based on array size, over rows\n",
    "torch.cat((x,x),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un tenseur peut être divisé en plusieurs morceaux. Ces petits morceaux peuvent être créés le long de lignes et de colonnes. L'exemple suivant montre un exemple de tenseur de taille (4,4). [documentation](https://pytorch.org/docs/stable/generated/torch.chunk.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function chunk:\n",
      "\n",
      "chunk(...)\n",
      "    chunk(input, chunks, dim=0) -> List of Tensors\n",
      "    \n",
      "    Splits a tensor into a specific number of chunks. Each chunk is a view of\n",
      "    the input tensor.\n",
      "    \n",
      "    Last chunk will be smaller if the tensor size along the given dimension\n",
      "    :attr:`dim` is not divisible by :attr:`chunks`.\n",
      "    \n",
      "    Arguments:\n",
      "        input (Tensor): the tensor to split\n",
      "        chunks (int): number of chunks to return\n",
      "        dim (int): dimension along which to split the tensor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.chunk) # on peut également utiliser la commande help pour obtenir la documentation de la fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8275,  0.2037,  0.0178, -1.1676],\n",
      "        [-0.5166, -1.5855,  0.9845, -0.7442],\n",
      "        [ 1.2453,  1.2474,  0.7227, -0.4241],\n",
      "        [ 0.3165, -1.8222,  0.2559, -0.9941]])\n",
      "tensor([[ 0.8275,  0.2037,  0.0178, -1.1676],\n",
      "        [-0.5166, -1.5855,  0.9845, -0.7442]])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(4, 4)\n",
    "print(a)\n",
    "chunk_tensor_one, chunk_tensor_two = torch.chunk(a,3)\n",
    "print(chunk_tensor_one)\n",
    "print(chunk_tensor_one.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.7511, -0.2865,  1.3605,  0.0829],\n",
       "         [-0.2232,  1.5162,  0.7597,  1.0610]]),\n",
       " tensor([[ 0.6291,  0.7295,  1.1682, -0.5936],\n",
       "         [ 1.7154,  0.2782, -1.6784,  0.2454]]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(a,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.7511, -0.2865],\n",
       "         [-0.2232,  1.5162],\n",
       "         [ 0.6291,  0.7295],\n",
       "         [ 1.7154,  0.2782]]),\n",
       " tensor([[ 1.3605,  0.0829],\n",
       "         [ 0.7597,  1.0610],\n",
       "         [ 1.1682, -0.5936],\n",
       "         [-1.6784,  0.2454]]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(a,2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La fonction gather collecte les éléments d'un tenseur et les place dans un autre tenseur à l'aide d'un argument d'index. La position de l'index est déterminée par la fonction LongTensor dans PyTorch.** [documentation](https://pytorch.org/docs/stable/generated/torch.gather.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 12.],\n",
       "        [23., 24.]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([[11,12],[23,24]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 12.],\n",
       "        [23., 12.]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(torch.Tensor([[11,12],[23,24]]), 0, \n",
    "             torch.LongTensor([[0,0],[1,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 0]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.LongTensor([[0,0],[1,0]]) \n",
    "#the 1D tensor containing the indices to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3541, -0.8554,  1.4224, -1.1067],\n",
      "        [ 2.2689, -2.2510, -1.0115,  0.3828],\n",
      "        [-1.0022,  0.0939, -1.5120,  0.8782],\n",
      "        [-0.8629, -0.9917,  0.8485,  0.7376]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4224, -1.1067],\n",
       "        [ 0.3828, -2.2510]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4, 4)\n",
    "print(a)\n",
    "torch.gather(a, 1, \n",
    "             torch.LongTensor([[2,3],[3,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.LongTensor([0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0403, -0.8753,  2.0183, -0.9703],\n",
       "        [-1.1656,  0.5954,  0.2671, -1.9146]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(a, 0, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0403,  2.0183],\n",
       "        [ 0.1292, -0.8912],\n",
       "        [-1.1656,  0.2671],\n",
       "        [ 0.4502,  0.3058]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(a, 1, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C'est une pratique courante de vérifier les valeurs non manquantes dans un tenseur, l'objectif est d'identifier les éléments non nuls dans un grand tenseur.** [documentation](https://pytorch.org/docs/stable/generated/torch.nonzero.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [2]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#identify null input tensors using nonzero function\n",
    "torch.nonzero(torch.tensor([10,0,23,0,0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [2]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(torch.Tensor([10,0,23,0,0.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La restructuration des tenseurs d'entrée en tenseurs plus petits accélère non seulement le processus de calcul, mais aide également au calcul distribué. La fonction split divise un long tenseur en plus petits tenseurs. [documentation](https://pytorch.org/docs/stable/generated/torch.split.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([12, 21]), tensor([34, 32]), tensor([45, 54]), tensor([56, 65]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the tensor into small chunks\n",
    "torch.split(torch.tensor([12,21,34,32,45,54,56,65]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([12, 21, 34]), tensor([32, 45, 54]), tensor([56, 65]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the tensor into small chunks\n",
    "torch.split(torch.tensor([12,21,34,32,45,54,56,65]),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Voyons maintenant des exemples de la façon dont le tenseur d'entrée peut être redimensionné compte tenu de la difficulté de calcul. La fonction de transposition est principalement utilisée pour remodeler les tenseurs. Il existe deux manières d'écrire la fonction de transposition : .t et .transpose.** [documentation](https://pytorch.org/docs/stable/generated/torch.transpose.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(3,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 4])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(3,2,4).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to reshape the tensors along a new dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7857,  0.3849,  0.2655, -0.1885, -0.9176],\n",
       "        [-0.1385,  1.7135, -0.2665,  1.3139,  0.6850],\n",
       "        [ 0.9837, -1.0935, -0.5328, -0.3283, -0.4980],\n",
       "        [ 0.4214, -0.0594, -1.1553, -0.4805,  0.7077]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7857, -0.1385,  0.9837,  0.4214],\n",
       "        [ 0.3849,  1.7135, -1.0935, -0.0594],\n",
       "        [ 0.2655, -0.2665, -0.5328, -1.1553],\n",
       "        [-0.1885,  1.3139, -0.3283, -0.4805],\n",
       "        [-0.9176,  0.6850, -0.4980,  0.7077]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t() #transpose is one option to change the shape of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose partially based on rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7857, -0.1385,  0.9837,  0.4214],\n",
       "        [ 0.3849,  1.7135, -1.0935, -0.0594],\n",
       "        [ 0.2655, -0.2665, -0.5328, -1.1553],\n",
       "        [-0.1885,  1.3139, -0.3283, -0.4805],\n",
       "        [-0.9176,  0.6850, -0.4980,  0.7077]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transpose(1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**La fonction unbind supprime une dimension d'un tenseur. Pour supprimer la ligne de dimension, la valeur 0 doit être transmise. Pour supprimer une colonne, la valeur 1 doit être transmise** [documentation](https://pytorch.org/docs/stable/generated/torch.unbind.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0190,  0.0220,  1.1532, -0.3393, -1.5380],\n",
       "        [-1.0248, -0.3781,  0.9257,  0.9247,  0.1825],\n",
       "        [-0.0737,  0.3147,  0.8504,  1.0534,  0.3692],\n",
       "        [ 0.0628, -0.3297, -1.7970,  0.8728,  0.7670]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0190, -1.0248, -0.0737,  0.0628]),\n",
       " tensor([ 0.0220, -0.3781,  0.3147, -0.3297]),\n",
       " tensor([ 1.1532,  0.9257,  0.8504, -1.7970]),\n",
       " tensor([-0.3393,  0.9247,  1.0534,  0.8728]),\n",
       " tensor([-1.5380,  0.1825,  0.3692,  0.7670]))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unbind(x,1) #dim=1 removing a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.7857,  0.3849,  0.2655, -0.1885, -0.9176]),\n",
       " tensor([-0.1385,  1.7135, -0.2665,  1.3139,  0.6850]),\n",
       " tensor([ 0.9837, -1.0935, -0.5328, -0.3283, -0.4980]),\n",
       " tensor([ 0.4214, -0.0594, -1.1553, -0.4805,  0.7077]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unbind(x) #dim=0 removing a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7857,  0.3849,  0.2655, -0.1885, -0.9176],\n",
       "        [-0.1385,  1.7135, -0.2665,  1.3139,  0.6850],\n",
       "        [ 0.9837, -1.0935, -0.5328, -0.3283, -0.4980],\n",
       "        [ 0.4214, -0.0594, -1.1553, -0.4805,  0.7077]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# comment calculer les fonctions mathématiques de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 23.,  3.])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(torch.FloatTensor([-10, -23, 3.000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20.0190, 20.0220, 21.1532, 19.6607, 18.4620],\n",
       "        [18.9752, 19.6219, 20.9257, 20.9247, 20.1825],\n",
       "        [19.9263, 20.3147, 20.8504, 21.0534, 20.3692],\n",
       "        [20.0628, 19.6703, 18.2030, 20.8728, 20.7670]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding value to the existing tensor, scalar addition\n",
    "torch.add(x,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0190,  0.0220,  1.1532, -0.3393, -1.5380],\n",
       "        [-1.0248, -0.3781,  0.9257,  0.9247,  0.1825],\n",
       "        [-0.0737,  0.3147,  0.8504,  1.0534,  0.3692],\n",
       "        [ 0.0628, -0.3297, -1.7970,  0.8728,  0.7670]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0381,  0.0440,  2.3064, -0.6787, -3.0759],\n",
       "        [-2.0497, -0.7561,  1.8515,  1.8494,  0.3651],\n",
       "        [-0.1474,  0.6294,  1.7008,  2.1068,  0.7384],\n",
       "        [ 0.1256, -0.6593, -3.5939,  1.7456,  1.5339]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar multiplication\n",
    "torch.mul(x,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7857,  0.3849,  0.2655, -0.1885, -0.9176],\n",
       "        [-0.1385,  1.7135, -0.2665,  1.3139,  0.6850],\n",
       "        [ 0.9837, -1.0935, -0.5328, -0.3283, -0.4980],\n",
       "        [ 0.4214, -0.0594, -1.1553, -0.4805,  0.7077]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les opérations mathématiques combinées, telles que l'expression d'équations linéaires sous forme d'opérations tensorielles, peuvent être effectuées à l'aide de l'exemple de script suivant. Ici, nous exprimons l'objet résultat y comme une combinaison linéaire des valeurs bêta multipliées par l'objet x indépendant, plus le terme constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how do we represent the equation in the form of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = intercept + (beta * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9534])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept = torch.randn(1)\n",
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2428,  0.4882],\n",
       "        [-1.7444, -2.9053]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7456"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = 0.7456\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1810,  0.3640],\n",
       "        [-1.3006, -2.1662]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(x,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4681,  1.1991],\n",
       "        [-1.0335, -2.1945]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x,beta,intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2315,  0.4655],\n",
       "        [-1.6631, -2.7699]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(intercept,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1810,  0.3640],\n",
       "        [-1.3006, -2.1662]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(x,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4125,  0.8295],\n",
       "        [-2.9637, -4.9361]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## y = intercept + (beta * x)\n",
    "torch.add(torch.mul(intercept,x),torch.mul(x,beta)) # tensor y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1117, -0.4966,  0.1631, -0.8817,  0.0539],\n",
       "        [ 0.6684, -0.0597, -0.4675, -0.2153, -0.7141],\n",
       "        [-1.0831, -0.5547,  0.9717, -0.5150,  1.4255],\n",
       "        [ 0.7987, -1.4949,  1.4778, -0.1696, -0.9919],\n",
       "        [-1.4569,  0.2563, -0.4030,  0.4195,  0.9380]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to round up tensor values\n",
    "torch.manual_seed(1234)\n",
    "torch.randn(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0., -0.,  1., -0.,  1.],\n",
       "        [ 1., -0., -0., -0., -0.],\n",
       "        [-1., -0.,  1., -0.,  2.],\n",
       "        [ 1., -1.,  2., -0., -0.],\n",
       "        [-1.,  1., -0.,  1.,  1.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.ceil(torch.randn(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1.,  0., -1.,  0.],\n",
       "        [ 0., -1., -1., -1., -1.],\n",
       "        [-2., -1.,  0., -1.,  1.],\n",
       "        [ 0., -2.,  1., -1., -1.],\n",
       "        [-2.,  0., -1.,  0.,  0.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.floor(torch.randn(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limiter les valeurs de n'importe quel tenseur dans une certaine plage peut être fait en utilisant l'argument minimum et maximum et en utilisant la fonction clamp. La même fonction peut appliquer le minimum et le maximum en parallèle ou l'un d'eux à n'importe quel tenseur, qu'il soit 1D ou 2D ; 1D est la version beaucoup plus simple. L'exemple suivant montre l'implémentation dans un scénario 2D.** [documentation](https://pytorch.org/docs/stable/generated/torch.clamp.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3000, -0.3000,  0.0000, -0.3000,  0.0000],\n",
       "        [ 0.0000, -0.3000, -0.3000, -0.3000, -0.3000],\n",
       "        [-0.3000, -0.3000,  0.0000, -0.3000,  0.4000],\n",
       "        [ 0.0000, -0.3000,  0.4000, -0.3000, -0.3000],\n",
       "        [-0.3000,  0.0000, -0.3000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# truncate the values in a range say 0,1\n",
    "torch.manual_seed(1234)\n",
    "torch.clamp(torch.floor(torch.randn(5,5)), min=-0.3, max=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3000, -0.3000,  0.0000, -0.3000,  0.0000],\n",
       "        [ 0.0000, -0.3000, -0.3000, -0.3000, -0.3000],\n",
       "        [-0.3000, -0.3000,  0.0000, -0.3000,  1.0000],\n",
       "        [ 0.0000, -0.3000,  1.0000, -0.3000, -0.3000],\n",
       "        [-0.3000,  0.0000, -0.3000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#truncate with only lower limit\n",
    "torch.manual_seed(1234)\n",
    "torch.clamp(torch.floor(torch.randn(5,5)), min=-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000, -1.0000,  0.0000, -1.0000,  0.0000],\n",
       "        [ 0.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [-2.0000, -1.0000,  0.0000, -1.0000,  0.3000],\n",
       "        [ 0.0000, -2.0000,  0.3000, -1.0000, -1.0000],\n",
       "        [-2.0000,  0.0000, -1.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#truncate with only upper limit\n",
    "torch.manual_seed(1234)\n",
    "torch.clamp(torch.floor(torch.randn(5,5)), max=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17.5031,  4.0656],\n",
       "        [-7.2563, -0.9320]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scalar division\n",
    "torch.div(x,0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.7564, 1.5016],\n",
       "        [0.4840, 0.9110]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute the exponential of a tensor\n",
    "torch.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.7564, 1.5016],\n",
       "        [0.4840, 0.9110]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to get the fractional portion of each tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11.7503, 10.4066],\n",
       "        [ 9.2744,  9.9068]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7503, 0.4066],\n",
       "        [0.2744, 0.9068]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.frac(torch.add(x,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the log of the values in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7503,  0.4066],\n",
       "        [-0.7256, -0.0932]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5598, -0.9000],\n",
       "        [    nan,     nan]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(x) #log of negatives are nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0636, 0.1653],\n",
       "        [0.5265, 0.0087]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to rectify the negative values do a power tranforamtion\n",
    "torch.pow(x,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounding up similar to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7503,  0.4066],\n",
       "        [-0.7256, -0.0932]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  0.],\n",
       "        [-1., -0.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  0.],\n",
       "        [-1., -0.]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.round(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Pour calculer les fonctions de transformation (c'est-à-dire sigmoïde, tangente hyperbolique, fonction de base radiale, etc., qui sont les fonctions de transfert les plus couramment utilisées dans l'apprentissage en profondeur), vous devez construire les tenseurs. L'exemple de script suivant montre comment créer une fonction sigmoïde et l'appliquer sur un tenseur.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7503,  0.4066],\n",
       "        [-0.7256, -0.0932]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8520, 0.6003],\n",
       "        [0.3262, 0.4767]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the square root of the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7503,  0.4066],\n",
       "        [-0.7256, -0.0932]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3230, 0.6376],\n",
       "        [   nan,    nan]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
